{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Pipe data - the features that are found to be relevent vary by location - suggests confounding underlying mixture process ...\n",
      "# Statistical methods may not have been applied correctly ... There may be a length bias ... the older pipes may sometimes appear \n",
      "# better as they are the ones that have survived the longest. \n",
      "\n",
      "# if underlying scores are distributed evenly, then by ranking we don't lose anything... If they are not then we do\n",
      "# How can we quantify this?\n",
      "\n",
      "# take two methods that generate scores - for simplicity probability scores in (0,1)\n",
      "\n",
      "# then combine them via rankings (or as individual scores)\n",
      "\n",
      "# A couple of possible situations 1) replications - features are the same - no unique information - differences will be due to noise\n",
      "# 2) different features led to scores\n",
      "\n",
      "# the binary issue would also be interesting to think about - when do we lose stuff by going to a classiciation problem. \n",
      "# When you have a kind of thresholding issue log logistic regression. \n",
      "\n",
      "# Lets start with 1). Generate a data set with a large number of features relative to observations, and rank features.\n",
      "# just do linear model with noise...\n",
      "\n",
      "def generateData(weights,instances):\n",
      "    n_features = weights.shape[0]\n",
      "    X = random.uniform(size=(n_features,instances))\n",
      "    Y = dot(W,X)\n",
      "    X = transpose(X)\n",
      "    return (X,Y)\n",
      "\n",
      "num_features = 100\n",
      "W = random.uniform(size = num_features)\n",
      "\n",
      "features1,target1 = generateData(W,10)\n",
      "features2,target2 = generateData(W,10)\n",
      "\n",
      "print features1.shape\n",
      "print target1.shape\n",
      "# do feature selection ... and compare how different the results are\n",
      "\n",
      "from sklearn import linear_model\n",
      "regr = linear_model.Lasso(alpha=.3)\n",
      "regr.fit(features1, target1)\n",
      "print regr.coef_ # very sparce output ... predicts only two coeficients are significant ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# pipe failure - causal\n",
      "\n",
      "# Cheng was talking about hypothisis testing each column individually as significant or not (to binary outcome) ...\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(10, 100)\n",
        "(10,)\n",
        "[-0.         -0.          0.         -0.          0.          0.          0.\n",
        "  0.         -0.          0.         -0.         -0.          0.         -0.\n",
        " -0.          0.         -0.         -0.          0.         -0.         -0.\n",
        "  0.          0.         -0.         -0.         -0.          0.         -0.\n",
        " -0.          0.         -0.          0.         -0.          0.         -0.\n",
        " -0.          0.          0.          0.          0.          0.          0.\n",
        " -0.          0.          0.         -0.          0.          0.         -0.\n",
        "  0.         -0.          0.          0.          0.         -0.         -0.\n",
        "  0.         -0.          0.          0.         -0.         -0.          0.\n",
        " -0.         -0.         -0.         -0.         -0.          0.\n",
        "  0.55310556  0.          0.          0.          0.          0.          0.\n",
        " -0.          0.          0.         -0.          0.         -0.         -0.\n",
        "  0.         -0.          0.         -0.         -0.          0.         -0.\n",
        " -0.          0.         -0.          0.         -0.          0.          0.\n",
        "  0.05069482  0.         -0.        ]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "diabetes = datasets.load_diabetes()\n",
      "diabetes_X_train = diabetes.data[:-20]\n",
      "diabetes_X_test  = diabetes.data[-20:]\n",
      "diabetes_y_train = diabetes.target[:-20]\n",
      "diabetes_y_test  = diabetes.target[-20:]\n",
      "print diabetes_X_train.shape\n",
      "print diabetes_y_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(422, 10)\n",
        "(422,)\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}

```{r}

train = read.csv("/home/finn/phd/data/logistic_train.csv")
test = read.csv("/home/finn/phd/data/logistic_test.csv")


# do the same thing with gmlnet
library('glmnet')
trainX = model.matrix(target~.,data=train)
trainy = train[,1]

# now how well does each of these models perform at predicting the test data ...
testX = model.matrix(target~.,data=test)
testy = test[,1]

alphas = seq(0,1,.1)
rs = data.frame(alpha = alphas,dev = rep(NA,length(alphas)))
i = 1
for (a in rs$alpha) {
  model = glmnet(trainX,trainy,alpha=a,family = "binomial")
  plot(model)
  pred = predict(model,newx=testX,type="response")
  deviance = colSums(-2*(log(pred)*testy + log(1-pred)*(1-testy)))
  plot(log(model$lambda),deviance)
  min_dev = min(deviance)
  rs[i,'dev']<-min_dev
  i <- i+1  
}




```

```{r}

lasso.pred = predict(model.lasso,newx=testX,type="response") # response is the probability between 0 and 1 of y==1
lasso.cpred = 1*(lasso.pred > 0.5)

dff = colSums(lasso.cpred == testy)/nrow(lasso.cpred) # count of correctly predicted instances 
deviance = colSums(-2*(log(lasso.pred)*testy + log(1-lasso.pred)*(1-testy)))
plot(log(model.lasso$lambda),dff)
plot(log(model.lasso$lambda),deviance)
# choose the optimal level of regularization based on deviance
best = which.min(deviance)
coef = predict(model.lasso,s=model.lasso$lambda[best],type='coefficients')
min_dev = min(deviance)

```
